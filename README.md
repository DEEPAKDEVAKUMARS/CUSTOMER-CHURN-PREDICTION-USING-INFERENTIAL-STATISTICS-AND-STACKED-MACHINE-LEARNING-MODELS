# CUSTOMER-CHURN-PREDICTION-USING-INFERENTIAL-STATISTICS-AND-STACKED-MACHINE-LEARNING-MODELS

Project Overview

This project aims to predict customer churn in the telecommunications industry using a combination of statistical analysis (ANOVA and Chi-square tests) and machine learning ensembles.
The model identifies customers who are most likely to discontinue services, allowing the company to take preventive actions and improve customer retention.

The dataset used is from the Telco Customer Churn dataset available on Kaggle

Objectives

To perform data preprocessing and handle categorical and numerical variables appropriately.

To apply ANOVA and Chi-Square tests for feature significance.

To build predictive models including:

CHAID-style Decision Tree

Logistic Regression

Random Forest

LightGBM

Stacked Ensemble (Meta-Learners: Logistic & LightGBM)

To evaluate the models based on ROC-AUC, Recall, F1-Score, and interpret the results.

Methodology

Data Preprocessing:
Missing values were handled, categorical columns were encoded, and numerical columns standardized.
The cleaned dataset was saved as churn_cleaned.csv.

Feature Significance Analysis:

ANOVA was used for numeric features.

Chi-Square test was applied for categorical features.

Only statistically significant predictors were retained for modeling.

Modeling:

CHAID Decision Tree

Logistic Regression

Random Forest

LightGBM

Stacked Meta-Learning Ensemble

Hyperparameter Optimization:
Optuna was used for fine-tuning Logistic and LightGBM meta-learners.

Evaluation Metrics:

Accuracy

Precision

Recall

F1-Score

ROC-AUC

Gains/Lift Analysis

Results Summary
Model	ROC-AUC	Accuracy	Recall	F1-Score
CHAID Decision Tree	0.8295	0.7197	0.8155	0.6070
Logistic Regression	0.8415	0.7381	0.7834	0.6136
Random Forest	0.8444	0.7551	0.7888	0.6310
Stacked (Meta-Logistic)	0.8453	0.7566	0.7914	0.6332
Stacked (Meta-LightGBM, Tuned)	0.8493	0.7991	0.5053	0.5719

Observation:
The tuned Meta-LightGBM ensemble achieved the best ROC-AUC of 0.8493, while Meta-Logistic offered a higher recall, ideal for churn-sensitive use cases.

Business Insight

The model reveals that contract type, tenure, and monthly charges are major churn determinants.
Customers with month-to-month contracts, high monthly bills, and no technical support are at the highest risk of leaving.
The predictions can be integrated into a CRM system to enable proactive retention strategies.

Tools and Technologies

Python 3.12

Scikit-Learn

LightGBM

Optuna

Pandas / NumPy

Matplotlib / Seaborn

Streamlit (optional deployment)

How to Run the Project
# Clone the repository
git clone https://github.com/<your-username>/Telco-Customer-Churn-Analysis.git
cd Telco-Customer-Churn-Analysis

# Install dependencies
pip install -r requirements.txt

# Run the notebook
jupyter notebook Customer_Churn_Prediction.ipynb


For Streamlit deployment (optional):

streamlit run streamlit_app.py

ğŸ“ Repository Structure
Telco-Customer-Churn-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”‚   â””â”€â”€ churn_cleaned.csv
â”‚   â””â”€â”€ splits/
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â”œâ”€â”€ meta_logistic_tuned.joblib
â”‚   â”œâ”€â”€ meta_lgb_tuned.joblib
â”‚   â””â”€â”€ preprocessor.joblib
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ anova_numeric_pvalues.png
â”‚   â”œâ”€â”€ chi2_categorical_pvalues.png
â”‚   â”œâ”€â”€ meta_ensemble_comparison.png
â”‚   â””â”€â”€ optuna_meta_lgb_param_importance.png
â”‚
â”œâ”€â”€ Customer_Churn_Prediction.ipynb
â”œâ”€â”€ streamlit_app.py
â””â”€â”€ README.md
